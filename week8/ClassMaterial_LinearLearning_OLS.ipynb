{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Models\n",
    "\n",
    "Dear students,\n",
    "\n",
    "finance data is most often in the format of a time-series. Time-series methods for predicting the return density are therefore one key element. Be reminded that the mean of that density would coincide with the expected return.\n",
    "\n",
    "The backbone of time series analysis is the linear regression model. In this section we are repeating all about regression work that one needs for financial data science work.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Tutorial and Revision Manual \n",
    "\n",
    "## B.1. Estimating Parameters of Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compact form of the Linear Regression Model is\n",
    "\n",
    "$$\n",
    "y := X\\; \\beta + \\epsilon, \\; \\epsilon :\\sim i.i.d.(0,\\sigma^2_{\\epsilon} I)\n",
    "$$\n",
    "\n",
    "with\n",
    "\n",
    "\\begin{align*}\n",
    "y &:= (y_1, y_2, ..., y_T)', \\text{observed}\\\\\\\\\n",
    "X &:= \\begin{pmatrix} \n",
    "\t\t\t\t\t\t\t\t\t\t\t1 & x_{11} & ... & x_{1p} \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t\t... & ... & ... & ... \\\\\n",
    "\t\t\t\t\t\t\t\t\t\t\t1 & x_{T1} & ... & x_{Tp} \n",
    "\t\t  \\end{pmatrix}; \\text{observed} \\\\\\\\\n",
    "\\beta &:= [\\beta_0, \\beta_1, ..., \\beta_p]'; \\text{unknown in real-life applications} \\\\\\\\\n",
    "\\epsilon &:= (\\epsilon_1, ..., \\epsilon_T)'; \\text{unknown in real-life applications}\n",
    "\\end{align*}\n",
    " \n",
    " \n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    " \n",
    "**Example:** Write AR(1) as LRM:    \n",
    "\n",
    "$$\n",
    "y_t := \\phi_0 + \\phi_1\\times y_{t-1} + \\epsilon_t; \\; \\epsilon_t \\sim iid(0,\\sigma^2_{\\epsilon}).\n",
    "$$\n",
    "\n",
    "coincides with\n",
    "\n",
    "\\begin{align*}\n",
    "y :&= X\\beta + \\epsilon \\\\\\\\\n",
    "\\underbrace{y}_{(T-1)\\times 1} &= (y_2, ..., y_T)'\\\\\\\\\n",
    "\\underbrace{X}_{(T-1) \\times 2} &= \\begin{pmatrix} 1 & y_1 \\\\ ... & ... \\\\ 1 & y_{T-1} \\end{pmatrix} \\\\\\\\\n",
    "\\underbrace{\\epsilon}_{(T-1)\\times 1} &= (\\epsilon_2, ..., \\epsilon_{T})' \\, :\\sim iid (0,\\sigma^2_{\\epsilon})\\\\\\\\\n",
    "\\beta &= (\\phi_0, \\phi_1)'.\n",
    "\\end{align*}\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "**Example:** Write ARMA(1,1) as LRM\n",
    "\n",
    "$$\n",
    "y_t := \\phi_0 + \\phi_1 y_{t-1} + \\theta_1 \\epsilon_{t-1} + \\epsilon_t, \\; \\epsilon_t :\\sim iid(0,\\sigma^2_{\\epsilon}).\n",
    "$$\n",
    "\n",
    "coincides with\n",
    "\n",
    "\\begin{align*}\n",
    "y = X\\beta + \\epsilon \\\\\\\\\n",
    "\\underbrace{y}_{(T-1)\\times 1} &= (y_2, ..., y_T)'\\\\\\\\\n",
    "\\underbrace{X}_{(T-1) \\times 3} &= \\begin{pmatrix} 1 & y_1 & \\epsilon_1 \\\\ ... & ... \\\\ 1 & y_{T-1} & \\epsilon_{T-1} \\end{pmatrix} \\\\\\\\\n",
    "\\underbrace{\\epsilon}_{(T-1)\\times 1} &= (\\epsilon_2, ..., \\epsilon_{T})' \\, :\\sim iid (0,\\sigma^2_{\\epsilon})\\\\\\\\\n",
    "\\underbrace{\\beta}_{3 \\times 1} &= (\\phi_0, \\phi_1, \\theta_1)'.\n",
    "\\end{align*}\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preferred Estimation Technique: Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLS provides **unbiased and consistent** estimates for $\\beta$, $\\sigma^2_{\\epsilon}$ and $\\epsilon$ if the data at hand shares the following characteristics:\n",
    "\n",
    "-  $X$ is **'weakly exogenous'**, i.e. measured without measurement error and effectively a constant for the problem\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "- **'linearity assumption'**, i.e. $y$ and any deterministic transformation of $X$ share a linear relationship; \n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "- **White Noise Residuals** \n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "- **Absence of Multi-Colinearity**  \n",
    "\n",
    " \n",
    " \n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "**OLS Parametric Solution**\n",
    "\n",
    " \n",
    "\\begin{align*}\n",
    " \\hat{\\beta}_{ols} :&= (X' X)^{{}-1} X' y \\\\\\\\\n",
    " \\hat{\\epsilon}_{ols} :&= y - X\\hat{\\beta}_{ols} \\\\\\\\\n",
    " \\hat{\\sigma}^2_{\\epsilon, ols}:&= \\frac{1}{T-p-1} \\; \\hat{\\epsilon}_{ols}' \\, \\hat{\\epsilon}_{ols} \\\\\\\\\n",
    " \\hat{var}_{ols}[\\beta] :&= \\hat{\\sigma}^2_{\\epsilon,ols}\\, \\times \\, (X' X)^{{}-1}  \\\\\\\\\n",
    "         \\hat{s.e.}_{ols}[\\beta_i] :&= \\sqrt{[\\hat{var}_{ols}[\\beta]]_{[i,i]}} \\qquad \\text{ for } i \\in [0,1,...,p] \\\\\\\\\n",
    " \\hat{t}_{ols}[\\beta_i] :&= \\frac{[\\hat{\\beta}_{ols}]_{[i,1]}}{\\hat{s.e.}_{ols}[\\beta_i]} \\\\\\\\\n",
    " \\hat{R}^2_{ols} :&= 1 - \\frac{(T-p-1) \\times \\hat{\\sigma}^2_{\\epsilon,ols} }{(T-1) \\times \\sigma^2_y }, \\text{where } \\sigma^2_y := \\frac{\\sum_{t=1}^T (y_t-\\bar{y})^2}{T-1}, \\text{where $\\bar{y}$ is the sample mean of $Y$} \\\\\\\\\n",
    "  \\hat{\\bar{R}}^2_{ols} :&= 1 - \\frac{\\hat{\\sigma}^2_{\\epsilon,ols}}{\\sigma^2_y} \\\\\\\\\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deriving Ordinary Least Squares Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OLS Objective Function:**\n",
    "\n",
    "\\begin{align*}\n",
    " \\hat{\\beta}_{ols} &:= \\min_{\\beta} \\; (y-X\\beta)' \\, (y-X \\beta),\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Notice, the OLS objective function is also called 'L2-minimization', each fitting error gets the same weight in the objective function (a result of the IID assumption on the error). \n",
    "\n",
    "\n",
    " \n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "**Re-write Objective Function**\n",
    "\n",
    "\\begin{align*}\n",
    " \\min_{{\\beta}} \\;y'y - 2 {\\beta}' \\, X'y + {\\beta}' \\, X'X \\, \\beta. \n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "**First-Order Condition (FOC) and Optimal Parameter Estimates:**\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{\\beta}_{ols} = (X' X)^{{}-1} X' y. \n",
    "\\end{align*}\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "Notice, $ (X' X)^{{}-1}$ exists if $X$ has full rank.\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "**Optimal Estimate for Variance of Residual:**\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{\\sigma}^2_{\\epsilon,ols} &= \\frac{1}{T-p-1} \\, (y - X\\hat{\\beta}_{ols})' \\, (y - X\\hat{\\beta}_{ols}),  \n",
    "\\end{align*}\n",
    "\n",
    " \n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "**Optimal Estimate of Residuals:**\n",
    " \n",
    "\\begin{align*}\n",
    "\\hat{\\epsilon}_{ols} = y - X\\hat{\\beta}_{ols}. \n",
    "\\end{align*}\n",
    "\n",
    "$$ \n",
    "\\\\ \\\\ \n",
    "$$\n",
    "\n",
    "**OLS, if applicable, is Unbiased:**\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{\\beta}_{ols} &= (X' X)^{{}-1} X' y \\nonumber \\\\ \\\\\n",
    "&=  (X' X)^{{}-1} X' (X\\beta + \\epsilon) \\\\\\\\\n",
    "&= (X' X)^{{}-1} X' X \\beta + (X' X)^{{}-1} X' \\epsilon \\nonumber \\\\\\\\\n",
    "&= \\beta + (X' X)^{{}-1} X' \\epsilon. \n",
    "\\end{align*}\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "E[\\hat{\\beta}_{ols}] = \\beta   \n",
    "$$\n",
    "\n",
    "\n",
    "because of weak-exogeneity assumption on $X$ which implies $E[X'\\epsilon]=0$.\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "**Precision of Parameter Estimates in terms of Variance:** \n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{\\beta}_{ols} - E[\\hat{\\beta}_{ols}] & = (X' X)^{{}-1} X' \\epsilon \\quad \\; \\rightarrow \\\\\\\\\n",
    "var(\\hat{\\beta}_{ols}) &= E\\left[(X' X)^{{}-1} X' \\epsilon \\, \\epsilon' \\, X (X' X)^{{}-1} \\right] \\\\ \\\\\n",
    "&= (X' X)^{{}-1} X' \\; \\sigma^2_{\\epsilon} I \\; X (X' X)^{{}-1} \\\\\\\\\n",
    "&= \\sigma^2_{\\epsilon} \\, \\times \\, (X' X)^{{}-1},\n",
    "\\end{align*}\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{var}_{ols}[\\beta] = \\hat{\\sigma}^2_{\\epsilon,ols}\\, \\times \\, (X' X)^{{}-1}.\n",
    "$$\n",
    "\n",
    "$$ \n",
    "\\\\ \\\\\n",
    "$$\n",
    "\n",
    "**OLS Standard Error:**\n",
    "\n",
    "\n",
    "$$\n",
    "\\hat{s.e.}_{ols}[\\beta_i] := \\sqrt{[\\hat{var}_{ols}[\\beta]]_{[i,i]}},\\quad \\forall i \\in [0,1,...,p]\n",
    "$$\n",
    "\n",
    "Notice, the standard error for $\\hat{\\sigma}^2_{\\epsilon}$ cannot be determined in the OLS set-up.  \n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "**OLS t-Stat:**\n",
    "\n",
    "\n",
    "$$\n",
    "\\hat{t}_{ols}[\\beta_i] := \\frac{[\\hat{\\beta}_{ols}]_{[i,1]}}{\\hat{s.e.}_{ols}[\\beta_i]}, \\quad \\; \\forall i \\in [0,...,p].\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\\\ \\\\ \n",
    "$$\n",
    "\n",
    "**OLS implied $R^2$:** \n",
    "\n",
    "\\begin{align*}\n",
    "R^2 &:= \\frac{var(X \\beta)}{var(y)} \\\\\\\\\n",
    "& = \\frac{var(y)-var(y-X \\beta)}{var(y)} \\nonumber \\\\\\\\\n",
    "& = 1-\\frac{var(y-X \\beta)}{var(y)} \\\\\\\\\n",
    "&= 1 - \\frac{(y-X\\hat{\\beta})'(y-X\\hat{\\beta})}{(y-\\bar{y})'(y-\\bar{y})}.  \n",
    "\\end{align*}\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "**OLS implied Adjusted $R^2$:** \n",
    "\n",
    "\\begin{align*}\n",
    "\\bar{R}^2 &:=   1-R^2 \\times \\frac{T-1}{T-p-1} \\\\\\\\\n",
    "&=  1 - \\frac{\\hat{\\sigma}^2_{\\epsilon,ols}}{\\sigma^2_y},\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "where \n",
    "\\begin{align*}\n",
    "\\sigma^2_y := \\frac{\\sum_{t=1}^T (y_t-\\bar{y})}{T-1}.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalizing the Concept of OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should start any regression work in finance with the notion that regression errors are not iid and that you need to apply some form of GLS estimator.\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "**Generalized Least Squres Regression Model** \n",
    "\n",
    "\n",
    "$$\n",
    "y = X\\beta + \\epsilon, \\; E[\\epsilon|X]=0; \\; Var(\\epsilon|X) = \\Sigma \\equiv \\sigma^2 \\Omega\n",
    "$$\n",
    "\n",
    "with $dim(\\Omega) = T\\times T$, $dim(X) = T \\times K$ and $dim(\\beta) = K \\times 1$.  \n",
    "\n",
    "\n",
    "Let's see by example what heteroscedastic, autocorrelated and homoscedastic errors look like.\n",
    "\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "**Applying OLS to a GLS Problem Makes Estimates Unbiased and Inefficient:**\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{\\beta}_{ols} &:= (X'X)^{-1} X'y \\\\\\\\\n",
    "&= \\beta + (X'X)^{-1} X'\\epsilon \\\\\\\\\n",
    "& \\rightarrow \\; E[\\hat{\\beta}_{ols}|X] = \\beta, \n",
    "\\end{align*}\n",
    "\n",
    "for as long as $E[\\epsilon|X]=0$ (i.e. weak exogeneity).\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "\\begin{align*}\n",
    "Var(\\hat{\\beta}_{ols}|X) &= E[(\\hat{\\beta}_{ols} - \\beta)^2|X] \\\\\\\\\n",
    "&= E[(X'X)^{-1} X'\\epsilon \\epsilon' X(X'X)^{-1}|X] \\\\\\\\\n",
    "&\\geq  \\sigma^2 (X'X)^{-1}.\n",
    "\\end{align*} \n",
    "\n",
    "Notice, if $\\epsilon|X \\sim N(0,\\Sigma)$, then \n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_{ols} \\sim N \\left(\\beta, \\qquad (X'X)^{-1} X'  \\Sigma X(X'X)^{-1} \\right).\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "**GLS differentiates two cases:**\n",
    "\n",
    "* Case 1: $\\Sigma$ is known (unrealistic case, useful for didactical purpose)\n",
    "\n",
    "\n",
    "* Case 2: $\\Sigma$ is unknown (realistic case)\n",
    "\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "**GLS Estimator for Case 1**\n",
    "\n",
    "\n",
    "If $\\Sigma$ is known, both $\\sigma^2$ and $\\Omega$ are known. Hence,\n",
    "\n",
    "$$\n",
    "\\Omega \\equiv C \\Lambda C',\n",
    "$$\n",
    "\n",
    "where $dim(C) = T \\times T$ matrix of eigenvectors and $dim(\\Lambda) = T\\times T$ diagonal matrix of eigenvalues. \n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "We define the rotation matrix $P$ \n",
    "\n",
    "$$\n",
    "P' := C \\Lambda^{-1/2}.\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "Next, we **rotate the GLR equation by P**  \n",
    "\n",
    "\\begin{align*}\n",
    "Py &= P X\\beta + P \\epsilon \\\\\\\\\n",
    "y^* &= X^* \\beta + \\epsilon^*.\n",
    "\\end{align*}\n",
    "\n",
    "To double check the intuition, each element of $y^*$ is a linear combination of the original $y$ elements. The same holds for $X^*$ and $\\epsilon^*$. \n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "Online lecture confirms that \n",
    "$$\n",
    "Var(\\epsilon^*|X) = \\sigma^2 \\times I.\n",
    "$$\n",
    "\n",
    " \n",
    "\n",
    "Hence, the OLS slope between $y^*$ and $X^*$ is called the GLS estimate of beta. It reads\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{\\beta}_{GLS} &= (X^{*'} X^*)^{-1} (X^{*'} y^*).\n",
    "\\end{align}\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "Next, we **rotate back:**\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{\\beta}_{GLS} &=  (X' \\, \\Omega^{-1} \\, X)^{-1} \\, (X' \\, \\Omega^{-1} \\, y).\n",
    "\\end{align}\n",
    "\n",
    " \n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "Note, as heteroscedasticity and auto-correlation make some regression errors larger than others, OLS misses to properly account for that when learning the slope coefficient. \n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "Note, if $\\Sigma$ and hence $\\Omega$ are known to the investor, then, the investor can weight each y/X observation by the variance of its regression error. This generalized learning scheme for beta will underweight observations that are generated by larger error variances and overweights observations with relatively small error variance terms.\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "Next, **appreciate:** $\\hat{\\beta}_{GLS}$ is the unbiased linear estimator of the GLRM with the highest precision (smallest variance) of\n",
    "$$\n",
    "Var(\\hat{\\beta}_{GLS}|X) = \\sigma^2 (X' \\, \\Omega^{-1} X)^{-1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "\n",
    "**GLS Estimator for Case 2**\n",
    "\n",
    "- Implementing  \n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_{GLS} = (X' \\, \\Omega^{-1} \\, X)^{-1} \\, (X' \\, \\Omega^{-1} \\, y)\n",
    "$$\n",
    "\n",
    "is **impossible** if $\\Sigma$ and hence $\\Omega$ **are unknown**. \n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "- Estimating  additional $T(T+1)/2$ parameters is not feasible.\n",
    "\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "Solving the problem using **Feasible GLS:**\n",
    "\n",
    "- run first a OLS solution for $\\beta$\n",
    "- then, calculate the sample covariance matrix $\\Sigma$ (and $\\Omega$)\n",
    "- then, re-run the GLS solution with that sample covariance matrix. \n",
    "- do that for a couple of rounds until convergence.\n",
    "\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "Alternatively, **apply OLS and compute robust standard errors:**\n",
    "\n",
    "- this OLS estimator will be unbiased, \n",
    "- consistent \n",
    "- and asymptotically normal, \n",
    "- yet, inefficient. \n",
    "\n",
    "- The robust standard errors are the White (1980) heteroscedastic covariance matrix, or even better, the Newey-West covariance matrix. \n",
    "\n",
    " \n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Measurement Error in OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**'Classical errors-in-variables model'**. \n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\underbrace{y}_{T \\times 1} &= \\underbrace{\\beta}_{1 \\times 1} \\underbrace{x}_{T \\times 1} + \\underbrace{\\epsilon}_{T \\times 1}.\n",
    "\\end{align*}\n",
    "\n",
    "- Assume, in data we do not measure $x$ but only $\\tilde{x}$, i.e.\n",
    "\n",
    "$$\n",
    "\\tilde{x} := x + u \\; \\text{with} \\; E[u] = 0; \\; Var(u) = \\sigma^2_u\n",
    "$$\n",
    "\n",
    "\n",
    "For simplicity, we assume\n",
    "\\begin{align*}\n",
    "&  plim \\frac{1}{T} (y'u) = 0 \\\\\\\\\n",
    "& plim \\frac{1}{T} (x'u) = 0 \\\\\\\\\n",
    "& plim \\frac{1}{T} (\\epsilon'u) = 0  \n",
    "\\end{align*}\n",
    " \n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "Plug the noisy measurement of $x$ into the population:\n",
    "\n",
    "\\begin{align*}\n",
    "y &= \\beta \\underbrace{(\\tilde{x} - u)}_{x} + \\epsilon \\\\\\\\\n",
    "&= \\beta \\tilde{x} + \\tilde{\\epsilon}, \\; \\tilde{\\epsilon} \\equiv \\epsilon - \\beta u.\n",
    "\\end{align*}\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "**Endogeneity Bias:** Error term of the regression (here, $\\tilde{\\epsilon}$) is correlated with the regressor, i.e.\n",
    "\n",
    "$$\n",
    "E[\\tilde{x}' \\tilde{\\epsilon}] \\neq 0,\n",
    "$$ \n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "**Magnitude of Engogeneity Bias:**\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{\\beta}_{ols} &= \\frac{cov(\\tilde{x},y)}{var(\\tilde{x})} \\\\\n",
    "&= \\frac{cov(x+u, \\beta x + \\epsilon)}{var(x+u)} \\\\\n",
    "&= \\beta \\times \\frac{Var(x)}{Var(x) + Var(u)},\n",
    "\\end{align*}\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "Ergo,\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_{ols} - \\beta = -\\frac{Var(u)}{Var(u) + Var(x)} \\times \\beta.\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Omitted Variable Bias and OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Suppose  \n",
    "\n",
    "\\begin{align*}\n",
    "y &= \\beta_0 + x_1 \\beta_1 + x_2 \\beta_2 + \\epsilon_y,\\; \\text{with} \\\\\\\\\n",
    "x_2 &= a + b\\times x_1 + \\epsilon_{x,2}, \n",
    "\\end{align*}\n",
    "\n",
    "where both epsilons are iid shocks. \n",
    "\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "Re-writing the last two equations \n",
    "\n",
    "\\begin{align*}\n",
    "y&= c + \\gamma x_1 + \\tilde{\\epsilon}_y, \\; \\text{with} \\\\\\\\\n",
    "c & \\equiv \\beta_0 + a\\beta_2 \\\\\\\\\n",
    "\\gamma & \\equiv \\beta_1 + b\\beta_2 \\\\\\\\\n",
    "\\tilde{\\epsilon}_y & \\equiv \\epsilon_y + \\beta_2\\epsilon_{x,2}.\n",
    "\\end{align*}\n",
    "\n",
    "Hence,\n",
    "\n",
    "\\begin{align*}\n",
    "& \\gamma > \\beta_1 \\quad \\text{for} \\quad b\\beta_2 > 0 \\\\\\\\\n",
    "& \\gamma < \\beta_1 \\quad \\text{for} \\quad b\\beta_2 < 0\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instrumental Variable Approach and OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The Instrumental Variable Approach can be viewed as a two-stage least squares problem\n",
    "\n",
    "* Stage 1: Project endogenous X-factor onto all exogenous X-factors and $I$\n",
    "\n",
    "\t\\begin{align*}\n",
    "\tX_{\\text{endog}} &= Z \\gamma + \\text{errors}, \\; Z \\equiv [X_{\\text{exog}} \\, I] \\\\\\\\\n",
    "\t\\rightarrow & \\hat{\\gamma}_{ols} = (Z'Z)^{-1} (Z'X_{\\text{endog}}) \\\\\\\\\n",
    "\t\\rightarrow & E[X_{\\text{endog}}| Z] = Z \\, (Z'Z)^{-1} (Z'X_{\\text{endog}}).\n",
    "\t\\end{align*}\n",
    "    \n",
    "    \n",
    "* Stage 2: Regress $y$ onto $X_{exog}$ and $E[X_{\\text{endog}}| Z]$\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{\\beta}_{ols,2sls} &= (\\tilde{X}' \\tilde{X})^{-1} (\\tilde{X'} y), \\; \\text{with}\\\\\\\\\n",
    "\\tilde{X} & \\equiv [X_{exog} \\quad E[X_{\\text{endog}}| Z]].\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Quizzes - Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MC_Qs_UnivariateTSModels import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**see ilias**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Exercises - Basics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.1 Linear Regression Model\n",
    "\n",
    "Consider the linear regression model $y = X \\beta + \\epsilon$. Define each term of the equation and explain why it is called a linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.2 MA(1) as LRM\n",
    "\n",
    "Write an MA(1) model as a linear regression problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.3 Linear Regression Model\n",
    "\n",
    "Assume a return factor of interest, $f_t$, follows a conditional Gaussian distribution with a one-step ahead  mean of $c + \\phi_f \\times f_{t-1} + \\theta_1 \\times \\epsilon_{t-1}$ and one-step ahead variance $\\sigma^2_{\\epsilon}$, where $c,\\phi,\\theta,  \\sigma^2_{\\epsilon}$ are constants and $\\epsilon$ being a forecast error. Write down the data generating process for $f_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.4 Estimating a LRM\n",
    "\n",
    "Write down a linear regression model. Highlight which parameters are to be estimated and also highlight the information that is used to pin down the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.5 OLS as Method of Choice\n",
    "\n",
    "Name the necessary data characteristics to ensure that OLS is the best estimation method of choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.6 Weak-Exogeneity\n",
    "\n",
    "Explain the concept of 'weak exogeneity'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.7 Linear Model\n",
    "\n",
    "Explain the concept of 'linearity' assumption in a linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.8 Multi-Collinearity\n",
    "\n",
    "Explain the concept and danger of multi-collinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.9 t-Statistics\n",
    "\n",
    "Write down the definition of the t-stat as a function of parameter estimate and sample volatility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.10 Variance Explained\n",
    "\n",
    "Write down the definition of $R^2$ and adjusted-$R^2$. Highlight similarities and differences of both quantities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.11 Objective Function OLS\n",
    "\n",
    "State the objective function of Ordinary Least Squares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.12 Graphical Interpretation of OLS\n",
    "\n",
    "Visualize the objective of Ordinary Least Squares using a two dimensional diagram where you plot the independent variable on the x-axis and the dependent variable on the y-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.13 L2 Minimization\n",
    "\n",
    "Explain the concept of L2 minimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.14 Algebra\n",
    "\n",
    "Verify that $(y-X\\beta)'(y-X\\beta)$ equals $y'y - 2\\beta'X'y + \\beta'X'X\\beta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.15 Optimization\n",
    "\n",
    "Find the $\\beta$ that minimizes $y'y - 2\\beta'X'y + \\beta'X'X\\beta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.16 Innovations\n",
    "\n",
    "Explain how to identify innovations in the response variable, assuming it follows a classical linear regression problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.17 Non-IID Errors\n",
    "\n",
    "Explain the meaning of regression errors being non-iid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.18 IID Errors\n",
    "\n",
    "Assume you observe $T$ observations of $y$ and $x$. The respective $\\epsilon$ vector has dimension $T \\times 1$ with covariance matrix $\\Sigma$. Specify $\\Sigma$ such that $\\epsilon$ is iid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.19 Heteroscedasticity\n",
    "\n",
    "Provide an investment related example for heteroscedastic regression errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.20 Auto-correlated Errors\n",
    "\n",
    "Provide an investment related example for auto-correlated errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.21 OLS when you should use GLS\n",
    "\n",
    "Assume you work with a Gaussian Generalized Linear Regression Model. Also assume, you estimate the slope coefficeints using OLS. What do you know about the distributional characteristic of that OLS estiamte?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.22 Rotation Matrix\n",
    "\n",
    "Explain the components and the meaning of the following rotation matrix $P' = C \\Lambda^{-1/2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.23 GLS Solution\n",
    "\n",
    "Consider the GLS problem with known covariance matrix of regression errors. State the GLS solution for the slope coefficient and ist precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.24 GLS Solution\n",
    "\n",
    "Consider the GLS problem with known covariance matrix of regression errors.  State the solution for the slope coefficient when using OLS and when using GLS. Provide intuition for the similarities and differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.25 Feasible GLS\n",
    "\n",
    "Explain how to run a FGLS estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.26 OLS vs FGLS\n",
    "\n",
    "Explain similarities and differences of the OLS vs FGLS solution for a Generalized Linear Regression Problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.27 Measurement Error\n",
    "\n",
    "Use an investment related example to illustrate what a measurement error is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E. Exercises - Challenging "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E.1 Estimating AR(2)\n",
    "\n",
    "Write down the DGP of an AR(2) model. Re-write the AR(2) as a linear regression model. Explain which variables are observed vs unobserved and why that model is called a linear model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E.2 Estimating ARMA(2,2)\n",
    "\n",
    "Write an ARMA(2,2) model as a linear regression model. Explain which variables are observed vs unobserved and why that model is called a linear model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E.3 Estimating AR(1)\n",
    "\n",
    "Write down the DGP of a AR(1) model with a constant intercept. Assume you observe a sample of 100 observations. Write down how to estimate the intercept, the slope coefficient, the variance of the error, their respective standard errors, t-stats and adjusted $R^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E.4 Unbiasedness of OLS\n",
    "\n",
    "Show that the OLS solution for the slope coefficient of a linear regression problem is unbiased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E.5 Precision of OLS Estimates\n",
    "\n",
    "Start with the assumption that the OLS estimate for $\\beta$ is unbiased. Next, determine the precision of the OLS estimate for $\\beta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E.6 Generalized Linear Regression Model\n",
    "\n",
    "Write down the GLS model and define each parameter and explain is meaning using investment relevant examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E.7 Estimating a Generalized Linear Regression Model\n",
    "\n",
    "Write down the GLS regression model. Explain two estimation approaches to estimate the parameters of the model. Characterize the statistical properties of each solution approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E.8 Errors-in-Variable Model\n",
    "\n",
    "Write down the classical errors-in-variables model. Show that if X is measured with error, the OLS estimate for the slope coefficient will be biased donwards. Also, characterize the size of the bias in terms of the magnitude of beta and the variances  of X and the measurement error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. 9 Measurement Errors\n",
    "\n",
    "Explain by example why it matters whether the indepedent or dependent variable is measured with error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E.10 Omitted Variable Bias\n",
    "\n",
    "Use a parametric example to explain the concept of an omitted variable bias. Show that the bias can be positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E.11 Instrumental Variable Approach \n",
    "\n",
    "Explain why the instrumental variable approach can be explained in terms of a two-stage least squares problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # F. Python for Financial Data Analysis\n",
    "\n",
    "Dear students,\n",
    "\n",
    "We approach the time-series modeling part as follows. First, you learn about ARMA models. Second, you learn how to siumulate these. Third, you learn how to estimate these. These estimations will lead us into the machine learning aspects of our course.\n",
    "\n",
    "We are currently learning about how to estimate the parameters and residuals of a linear model. Our application of choice are ARMA models. \n",
    "\n",
    "I provide you with a set of Python applications for estimating linear regression problems. Our application builts on the 3-month government bond yield that you have seen in the Python part on \"statistical arbitrage\". In that application you found out that an AR(3) model for that interest rate has maximum support. Hence, here I do: (i) fit an AR(3)  3-month government bond yield), (ii) extract point estimates for parameters, extract the time-series of the residual and its volatility, (iii) quantify the precision of the parameter estimates in terms of t-stats and standard errors, (iv) quantify how much of interest rate movements are predictable (in-sample). In order to really learn, we will not use packages but rather code everything from scratch.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F.1 Preparing y and X for Fitting an AR(3)\n",
    "\n",
    "In our example, we want to fit the level of the 3-month government bond yield (monthly data) onto its past 3 lags. Hence,\n",
    "\n",
    "$$\n",
    "y_t = \\text{3-month gov bond yield at time t}\n",
    "$$\n",
    "\n",
    "$$\n",
    "X_t = \\text{constant} | y_{t-1}    |  y_{t-2} | y_{t-3}.\n",
    "$$\n",
    "\n",
    "Note: It is always a good idea to add a constant to the regression.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zero**, load packages that we rely upon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# econometric work\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    " \n",
    "\n",
    "# plotting  \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First**, read-in the data. A panel of interest rates is in the file \"GovBondYields.xls\". It contains monthly gov bond yiels of maturities 3months to 10 years for the period 1954 to 2006."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data: Term Structure of Interest Rates\n",
    "data = pd.read_excel('GovBondYields.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>3</th>\n",
       "      <th>6</th>\n",
       "      <th>12</th>\n",
       "      <th>24</th>\n",
       "      <th>36</th>\n",
       "      <th>60</th>\n",
       "      <th>84</th>\n",
       "      <th>120</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1954-04-01</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.940464</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.20922</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.92921</td>\n",
       "      <td>2.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date     3         6    12       24    36    60       84   120\n",
       "0 1954-04-01  0.97  0.940464  0.96  1.20922  1.54  1.87  1.92921  2.29"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1) #visualize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the column \"Date\" to be the index of the pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>6</th>\n",
       "      <th>12</th>\n",
       "      <th>24</th>\n",
       "      <th>36</th>\n",
       "      <th>60</th>\n",
       "      <th>84</th>\n",
       "      <th>120</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1954-04-01</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.940464</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.20922</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.92921</td>\n",
       "      <td>2.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             3         6     12       24    36    60       84    120\n",
       "Date                                                                \n",
       "1954-04-01  0.97  0.940464  0.96  1.20922  1.54  1.87  1.92921  2.29"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1) #double check we got what we wanted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call the 3-month gov yield \"r\". The headings suggest that \"3\" stands for 3-month yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fdcbd245fd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r.plot() #double check the units of r and whether the overall shape is what you expected it to be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, $r$ is persistent. A previous exercise found out that an AR(3) has the lowest AIC value. This motivates us to fit an AR(3) to $r$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second**, we bring the AR(3) for $r$ into the regression notation $y=X \\beta + \\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of time points coincide with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I like to start with specifying $y$. Here, y contains the time $t$ realization of $r$ and maps it onto its last three lags. Hence, the first start value for $r$ can only start in $r[3]$, so that it can be mapped to $r[2], r[1], r[0]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = r[3:T] #_df highlights its a pandas data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For numerical computations, it might be more convenient to work with numpy matrices. So, I rewrite $y_df$ as a numpy matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.matrix(y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 622)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape #double check the dimension of y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want $y$ to be a column vector (here as a matrix variable) with dimension $(T-3) \\times 1$. So, I reshape it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =  y.reshape(T-3,1) # nice looking column vector (in matrix format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y) # double check length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create $X$, the explanatory variables. I like to start with the lag 1 variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rLag1 = r[2:T-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rLag1) # double check the length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I move on to lag 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rLag2 = r[1:T-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rLag2) # double check the length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, lag 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rLag3 = r[0:T-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rLag3) #double check the length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we put a constant and these three lags into a matrix $X$. We use the logic from above. We create $X$ as a pandas data frame and later over-write it as a numpy matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our regression constant is called \"ones\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.ones(T-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize $X$_df with the constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add the values of the pandas data frame for all three lag variables to $X$_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df[\"rLag1\"] = rLag1.values\n",
    "X_df[\"rLag2\"] = rLag2.values\n",
    "X_df[\"rLag3\"] = rLag3.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we reformat $X$_df as a numpy matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X             = np.matrix(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(622, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape #double check it has the dimensions you expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Third**, now, you can give $y$ and $X$ to a regression package of your choice to fit y onto X. \n",
    "\n",
    "I continue below with coding up my own package. I use the notation from my lecture above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F.2 Find Point Estimates and Volatility of Residual for AR(3) Model on the 3-month Gov Yield"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First**, we collect the key formula from above\n",
    "\n",
    "\\begin{align*}\n",
    " \\hat{\\beta}_{ols} :&= (X' X)^{{}-1} X' y \\\\\\\\\n",
    " \\hat{\\epsilon}_{ols} :&= y - X\\hat{\\beta}_{ols} \\\\\\\\\n",
    " \\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second**, I choose a \"divide an conquer strategy\". I devide the math formula into sub problem. And, I use notation that is self expanalatory given the above latex formula\n",
    "\n",
    "I start with $(X'X)^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpxi = (X.getT() * X).getI() #it is OK to use a package for transpose and inversion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For follow up work, I recommend to always flag an inversion. That is were numerical issues can cook up. My preferred way is to check that the eigenvalues of $X'X$ are positive. This ensures the term is invertible. I talk about eigenvalues and principal components in the master class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.00721336, -0.00090918,  0.0005602 , -0.0007273 ],\n",
       "        [-0.00090918,  0.00887018, -0.01174648,  0.00304389],\n",
       "        [ 0.0005602 , -0.01174648,  0.02337232, -0.01173236],\n",
       "        [-0.0007273 ,  0.00304389, -0.01173236,  0.00883406]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xpxi #at least the matrix is non-NAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Third**, Now I continue to compute the OLS estimate for $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_ols = xpxi * (X.getT() * y) #const, rLag1, rLag2, rLag3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am so excited to see whether the coefficients are close to 0 or close to 1, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.08678418],\n",
       "        [ 1.39377645],\n",
       "        [-0.61199535],\n",
       "        [ 0.20253518]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_ols #huuh: rLag1 has a loading of 1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, an AR(1) with loading of equal or larger than 1 says that the data is non-stationary. In our AR(3) application, the loading on lag1 is larger than 1, yet, at least one of the other lags has a negative loading. We can hence not say that data is non-stationary. For that we would have to run a formal stationarity test. Yet, as a theory oriented person, I treat interest rates as a stationary quantity, which I know is just very persistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fourth**, often overlooked, hence, I highlight it, get the respective time series of the residuals. In economic terms, this teaches you about the realized shocks to interest rates. Get back to me with suggestions of what could be the reason for interest rate shocks being non zero (!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_ols = y - X * beta_ols #ensure the X and beta_ols dimensions add up and match dim(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdcbd53bad0>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_df.index, eps_ols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fifth**, looking at the results and connecting it to what really happened in the world...\n",
    "\n",
    "Wow, the earthquake like movements around 1980s are NO statistical artefact. The U.S. economy had troubles around that time. Inflation moved in the late 1970s to 16\\%. The Fed Chairman Paul Volcker raised the short term policy rate (Federal funds rate) to levels of 16\\%, which created a recession. Then, he lowered it again, before, he again raised it to cause a second recession. In the end, inflation came back to levels of around 4-2\\% and the aftermath is called the period of the Great Moderation. You see that in the interest rate shocks. Later in the course, you will also learn, why you can extract from such a figure that the volatility of the residual is most likely NOT a constant, but time-varying. You even learn here already that volatility clusters. You see that in the picture. Around 1980, there were huge interest rate shocks, likely because of a hightend standard deviation (vol), while afterwards, the vol must have been way smaller, as we do not observe large shocks in that period of the Great Moderation.\n",
    "\n",
    "Isn't it fascinating what a $\\epsilon$ can tell you about history(!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sixth**, finally, we compute the volatility of the residual (interest rate shock). The respective formula from class  is\n",
    "\n",
    "$$\n",
    "\\hat{\\sigma}^2_{\\epsilon, ols}:= \\frac{1}{T-p-1} \\; \\hat{\\epsilon}_{ols}' \\, \\hat{\\epsilon}_{ols} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_eps_ols = 1 / (len(y) - 3 - 1) * (eps_ols.getT() * eps_ols) \n",
    "\n",
    "vol_eps_ols = np.sqrt(var_eps_ols) #unconditional vol of residual, unconditional vol of interest rate shock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you understands the units of the vol, i.e. is it in decimals or percent, is it annualized or in monthly units?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41818919641730506"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol_eps_ols[0,0] #what are the units?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the units, $\\epsilon$ has the units of $y$ and $X$. The latter were annualized and in percent. Hence, vol_eps_ols is annualized and in percent. \n",
    "\n",
    "It says that the interest rate shock has an annualized volatility of 0.42\\%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F.3 Quantify the Precision of the Parameter Estimates in Terms of t-stats and Standard Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First**, the key question here is: \"how informative was the data for $\\beta$\"? This is the same question than asking \"how large are the standard errors on the point estimate of $\\beta$?\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second**, we collect the necessary OLS formula for the standard error. Note, we first compute the variance matrix of the beta estimates, which quantifies the uncertainty around the point estimate. Then, we compute the standard error out of the matrix. The latter is then transformed into the t-statistic...\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{var}_{ols}[\\beta] :&= \\hat{\\sigma}^2_{\\epsilon,ols}\\, \\times \\, (X' X)^{{}-1}  \\\\\\\\\n",
    " \\hat{s.e.}_{ols}[\\beta_i] :&= \\sqrt{[\\hat{var}_{ols}[\\beta]]_{[i,i]}} \\text{ for } i \\in [0,1,...,p] \\\\\\\\\n",
    " \\hat{t}_{ols}[\\beta_i] :&= \\frac{[\\hat{\\beta}_{ols}]_{[i,1]}}{\\hat{s.e.}_{ols}[\\beta_i]} \\\\\\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Third**, I implement the above formulas in a \"divide and conquer strategy\". I start with what I call a bit loosely the precision matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "varMatrix_beta = var_eps_ols[0,0] * xpxi # its a full matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.26148817e-03, -1.59000101e-04,  9.79684831e-05,\n",
       "         -1.27191390e-04],\n",
       "        [-1.59000101e-04,  1.55123702e-03, -2.05425040e-03,\n",
       "          5.32321828e-04],\n",
       "        [ 9.79684831e-05, -2.05425040e-03,  4.08740340e-03,\n",
       "         -2.05178122e-03],\n",
       "        [-1.27191390e-04,  5.32321828e-04, -2.05178122e-03,\n",
       "          1.54492053e-03]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varMatrix_beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I really need only the diagonal elements for the standard errors. Here, it goes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdErrors_beta_ols = np.sqrt(varMatrix_beta.diagonal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.03551743, 0.03938575, 0.0639328 , 0.03930548]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stdErrors_beta_ols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard errors are only meaningful in relation to the magnitude of the point estimates. Hence, we standardize these and obtain the t-statistic.\n",
    "\n",
    "Before we devide or multiply quantities, we want to ensure that the dimensions are as we expect them to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_ols.shape #4x1 vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stdErrors_beta_ols.shape #aha! The dimension is not as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we first have to reshape stdError_beta_ols to a $4 \\times 1$ columnvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdErrors_beta_ols = stdErrors_beta_ols.reshape(4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stdErrors_beta_ols.shape #nice! now we got the dimension we need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now, we can run an element-wise division to get the t-stat for each parameter estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tStat_beta_ols = beta_ols / stdErrors_beta_ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 2.44342479],\n",
       "        [35.3878389 ],\n",
       "        [-9.57247795],\n",
       "        [ 5.1528489 ]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tStat_beta_ols #nice! highly significant parameters. That is what a data scientist wants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fourth**, interpretation: The lags are highly significant. The most significant one is Lag1. That is not surprising and also the reason why an AR(1) would capture already most of the auto correlation in interest rates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fifth**, one thing that is missing! Check whether the residuals are iid. One way to do that is to fit an AR(1) to the residuals and check whether the loading on the lag parameter is insignificant. I leave that to you as an exercise....\n",
    "\n",
    "Also, later in the course, you understand why you could repeat this regression for the squared of the interest rate shocks. In fact, this will be a test whether the volatility of the epsilon shock is constant. It needs to be constant for an iid shock. ... I am awaiting your questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F.4 Quantify How Much of Interest Rate Movements are Predictable (in-sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different ways to approach this question. I prefer to look at the $R^2$ and adjusted $R^2$. \n",
    "\n",
    "Let's collect the appropriate formulas\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{R}^2_{ols} :&= 1 - \\frac{(T-p-1) \\times \\hat{\\sigma}^2_{\\epsilon,ols} }{(T-1) \\times \\sigma^2_y }, \\text{where } \\sigma^2_y := \\frac{\\sum_{t=1}^T (y_t-\\bar{y})^2}{T-1}, \\text{where $\\bar{y}$ is the sample mean of $Y$} \\\\\\\\\n",
    "  \\hat{\\bar{R}}^2_{ols} :&= 1 - \\frac{\\hat{\\sigma}^2_{\\epsilon,ols}}{\\sigma^2_y} \\\\\\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will go directly for the adjusted $R^2$ as we are in a multivariate setting. So, I simply subtract the ratio of unexplained variance over total variance from 1. Lets do that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dm =  y-y.mean() #622x1, demeand y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sum up the second power of the last term via a multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_dm = y_dm.T * y_dm #still a numpy matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we divide the latter by $T-1$ to get the variance of $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_y = y2_dm  / (T-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adjusted R2 comes out as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjR2_ols = 1 - var_eps_ols[0,0] / var_y[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.977722115777261"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjR2_ols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearly 98\\% in-sample predictability for monthly variations of the 3-month gov bond yield. \n",
    "\n",
    "At the Chair be played aroudn predicting interest rates using nonlinear regressions, which we call nowadays neural networks. The result was that beating a linear model for interest rates is nearly impossible. The high R2 is one indication for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}