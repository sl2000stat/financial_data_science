{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E.2 MLE for Gaussian AR(1)-GARCH(1,1)\n",
    "\n",
    "Fit a Gaussian AR(1)-GARCH(1,1) to the 10-year government bond yield. Use the following procedure:\n",
    "\n",
    "1. Write a function, called \"garch11_variance(alpha_0, alpha_1, beta_1, sigma2_1, epsilon)\". It takes the parameters of the variance equation as an input as well as the residuals of the mean equation. The function returns the GARCH(1,1) implied variance. Note, the first variance is computed using \"epsilon[0]\" and the start value of the variance, i.e. \"sigma2_1\". \n",
    "\n",
    "2. Write a second function, called, \"Neg_loglikelihood_ar1_Garch11(parameters)\". It takes the model parameters as input and returns the negative joint log likelihood function. \n",
    "\n",
    "3. Use smart starting values for the optimization (from last week's Python for Financial Data Science material, see below). In addition, we use rather uninformative starting values for beta and sigma2_1, namely 0.01 and 1, respectively. **Praktomat: estimated parameters from local unconstrained optimization**\n",
    "\n",
    "4. You want to use a bounded optimizer to ensure the estimate imply: (i) stationary interest rates (stationary mean equation), (ii) positive unconditional interest rates, (iii) stationary variance of interest rates (stationary variance equation), (iv) positive unconditional variance of interest rate. **Type of optimizer: differential_evolution**. **Praktomat: estimated parameter global constrained optimization**\n",
    "\n",
    "5. Hand-in the mathematical algorithm and pseudo code that underlines your Python implementation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudocode for the AR(1)-GARCH(1,1) Model:\n",
    "\n",
    "Ar model:\n",
    "\\begin{equation}\n",
    "r_t = \\phi_0 + \\phi_1 r_{t-1} + epsilon_t\n",
    "\\end{equation}\n",
    "\n",
    "Garch model:\n",
    "\\begin{equation}\n",
    "\\sigma^2_t = \\alpha_0 + \\alpha_1 \\epsilon^2_{t-1} + \\beta_1 \\sigma^2_{t-1}, s.t. \\sigma^2_1 = \\text{known parameter}\n",
    "\\end{equation}\n",
    "\n",
    "thus the Likelyhood function is as follows:\n",
    "\\begin{equation}\n",
    "L_T(\\phi_0, \\phi_1, \\alpha_0, \\alpha_1, \\beta_1, \\sigma_1) = \\prod_{t=2}^T \\frac{1}{\\sqrt{ 2 \\pi (\\alpha_0 + \\alpha_1 \\epsilon^2_{t-1} + \\beta_1 \\sigma^2_{t-1})}} \\times \\exp\\left( -\\frac{(r_t - [\\phi_0 + \\phi_1 r_{t-1}])^2}{2 (\\alpha_0 + \\alpha_1 \\epsilon^2_{t-1}+ \\beta_1 \\sigma^2_{t-1})} \\right)\n",
    "\\end{equation}\n",
    "\n",
    "and the log Likelihood function:\n",
    "\\begin{equation}\n",
    " \\ln (L_T(.)) = \\sum_{t=2}^T -\\frac{1}{2} \\ln(2\\pi [\\alpha_0 + \\alpha_1 \\epsilon^2_{t-1}+ \\beta_1 \\sigma^2_{t-1}]) - \\frac{1}{2}  \\frac{(r_t - [\\phi_0 + \\phi_1 r_{t-1}])^2}{2 (\\alpha_0 + \\alpha_1 \\epsilon^2_{t-1}+ \\beta_1 \\sigma^2_{t-1})}\n",
    "\\end{equation}\n",
    "\n",
    "Instructions:\n",
    "Compute the Ar model and get the residuals therefrom\n",
    "\n",
    "Compute the conditional Vraiance: Garch model by using the residuals from the Ar model as well as a starting value\n",
    "Use an Iterative approach to compute the variance in a \"rolling window\".\n",
    "\n",
    "Take the variance and residuals and plug them into the log likelihood function\n",
    "\n",
    "Use the given optimiziers to find the best Vale for the parameters\n",
    "\n",
    "further descriptions by comments and code itself\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Data**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "# import needed packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize\n",
    "\n",
    "def set_time_index(df, timecolname):\n",
    "\n",
    "    \"\"\"This function sets the time col as index and makes sure it's a datetime object.\n",
    "\n",
    "    :param df: full Dataframe\n",
    "    :param timecolname: colname of the column that has time information in it\n",
    "    :return: full Dataframe\n",
    "    \"\"\"\n",
    "    # take the time column and convert it to a datetime object\n",
    "    df[timecolname] = pd.to_datetime(df[timecolname])\n",
    "\n",
    "    # set the index of the DF as the time Column\n",
    "    df.set_index(timecolname, inplace = True)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the needed data\n",
    "df_bond = pd.read_excel(\"GovBondYields.xls\",sheet_name=\"Rates\",header=0)\n",
    "df_bond = set_time_index(df_bond,\"Date\")\n",
    "\n",
    "# get the 10 year bond\n",
    "r_t = df_bond.iloc[:,7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LL**\n",
    "\n",
    "\\begin{equation}\n",
    "L_T(\\phi_0, \\phi_1, \\alpha_0, \\alpha_1, \\beta_1, \\sigma_1) = \\prod_{t=2}^T \\frac{1}{\\sqrt{ 2 \\pi (\\alpha_0 + \\alpha_1 \\epsilon^2_{t-1} + \\beta_1 \\sigma^2_{t-1})}} \\times \\exp\\left( -\\frac{(r_t - [\\phi_0 + \\phi_1 r_{t-1}])^2}{2 (\\alpha_0 + \\alpha_1 \\epsilon^2_{t-1}+ \\beta_1 \\sigma^2_{t-1})} \\right)\n",
    "\\end{equation}\n",
    "\n",
    "with $\\sigma^2_t = \\alpha_0 + \\alpha_1 \\epsilon^2_{t-1} + \\beta_1 \\sigma^2_{t-1}, s.t. \\sigma^2_1 = \\text{known parameter}$\n",
    "\n",
    "Note:\n",
    "\\begin{equation}\n",
    " \\ln (L_T(.)) = \\sum_{t=2}^T -\\frac{1}{2} \\ln(2\\pi [\\alpha_0 + \\alpha_1 \\epsilon^2_{t-1}+ \\beta_1 \\sigma^2_{t-1}]) - \\frac{1}{2}  \\frac{(r_t - [\\phi_0 + \\phi_1 r_{t-1}])^2}{2 (\\alpha_0 + \\alpha_1 \\epsilon^2_{t-1}+ \\beta_1 \\sigma^2_{t-1})} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**function GARCH_11_VARIANCE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def garch11_variance_new(alpha_0, alpha_1, beta_1, sigma2_1, epsilon):\n",
    "    \"\"\"\n",
    "    :param alpha_0: param variance equation\n",
    "    :param alpha_1: param variance equation\n",
    "    :param beta_1: param variance equation\n",
    "    :param sigma2_1: param variance equation\n",
    "    :param epsilon: residuals from mean equation\n",
    "    :return: implied Garch (1,1) Variance\n",
    "    \"\"\"\n",
    "\n",
    "    # if alpha_0 < 0:\n",
    "    #     print(\"alpha0 is negative\")\n",
    "    #     print(alpha_0)\n",
    "\n",
    "    # if alpha_1 < 0:\n",
    "    #     print(\"alpha1 is negative\")\n",
    "    #     print(alpha_1)\n",
    "\n",
    "    # if beta_1 < 0:\n",
    "    #     print(\"beta is negative\")\n",
    "    #     print(beta_1)\n",
    "\n",
    "    # get the starting value\n",
    "    sig2_initial = (alpha_0 + alpha_1 * epsilon[0]**2) + beta_1 * sigma2_1\n",
    "\n",
    "    # get the starting value into a list\n",
    "    save = [sig2_initial]\n",
    "\n",
    "    # remove the first epsilon as we already used it to compute the first variance\n",
    "    epsilon = epsilon[1:]\n",
    "\n",
    "    # for each epsilon\n",
    "    for i in range(len(epsilon)):\n",
    "\n",
    "        # compute the variance by garch formula and take the last value of the array\n",
    "        sig2 = alpha_0 + alpha_1 * epsilon[i]**2 + beta_1 * save[i]\n",
    "               # + beta_1 * save[i]\n",
    "\n",
    "        # save value to array\n",
    "        save.append(sig2)\n",
    "\n",
    "    # convert list to numpy array\n",
    "    save = np.array(save)\n",
    "\n",
    "    return save\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-ln(L_T)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_loglikelihood_ar1_Garch11(parameters, r_t):\n",
    "    \"\"\"\n",
    "    :param parameters: list of parameters\n",
    "    :param r_t: pandas series of wanted infromation\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    phi_0   = parameters[0]\n",
    "    phi_1   = parameters[1]\n",
    "    alpha_0 = parameters[2]\n",
    "    alpha_1 = parameters[3]\n",
    "    beta_1 =  parameters[4]\n",
    "    sig_1 =  parameters[5]\n",
    "\n",
    "    # get the conditional mean by ar(1) model (remove last row from r_t)\n",
    "    mean = phi_0 + phi_1 * r_t.iloc[:-1].values\n",
    "\n",
    "    # compute the residuals from rt (delete first row from r-t)\n",
    "    resid  = r_t.iloc[1:].values - mean\n",
    "\n",
    "    # get the variance\n",
    "    vars = garch11_variance_new(alpha_0, alpha_1, beta_1, sig_1, resid[:-1])\n",
    "\n",
    "    # compute the likelyhood\n",
    "    loglikeli = np.sum(-0.5 * np.log(2 * np.pi * vars) - (r_t.iloc[2:].values - mean[1:])**2 / (2 * vars))\n",
    "\n",
    "    return -loglikeli\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start Values from 2pass Estimation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "4290.227857000036\n"
     ]
    }
   ],
   "source": [
    "#start values for AR(1)-GARCH(1,1) parameters from last week's Python for Financial Data Science material\n",
    "phi0_start = 0.0204\n",
    "phi1_start = 0.9962\n",
    "alpha0_start = 0.0004\n",
    "alpha1_start = 0.3157\n",
    "#uninformative start values for GARCH part\n",
    "beta1_start = 0.01\n",
    "sigma2_1_start = 1\n",
    "\n",
    "# example call\n",
    "ar1_garch11_params_start = [phi0_start,phi1_start,alpha0_start,alpha1_start,beta1_start,sigma2_1_start]\n",
    "print(neg_loglikelihood_ar1_Garch11(ar1_garch11_params_start,r_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unconstrained Optimization: Nelder-Mead Optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-145-6483aba02dda>:15: RuntimeWarning: invalid value encountered in log\n",
      "  loglikeli = np.sum(-0.5 * np.log(2 * np.pi * vars_) - (r_t.iloc[2:].values - means[1:])**2 / (2 * vars_))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " final_simplex: (array([[-9.42909819e-02,  1.02272100e+00,  6.72904750e-03,\n",
      "         4.44254154e+00,  3.78591364e-03, -1.89650414e+01],\n",
      "       [-9.43678041e-02,  1.02273338e+00,  6.72870640e-03,\n",
      "         4.44201946e+00,  3.78959166e-03, -1.89587335e+01],\n",
      "       [-9.43805065e-02,  1.02273580e+00,  6.72509682e-03,\n",
      "         4.43950248e+00,  3.79069163e-03, -1.89425096e+01],\n",
      "       [-9.43291515e-02,  1.02272597e+00,  6.72679589e-03,\n",
      "         4.44086270e+00,  3.78849881e-03, -1.89530582e+01],\n",
      "       [-9.42825107e-02,  1.02272182e+00,  6.72645611e-03,\n",
      "         4.44080260e+00,  3.78555321e-03, -1.89545001e+01],\n",
      "       [-9.43404076e-02,  1.02272532e+00,  6.72861485e-03,\n",
      "         4.44206732e+00,  3.78901032e-03, -1.89601350e+01],\n",
      "       [-9.43890910e-02,  1.02273693e+00,  6.72550876e-03,\n",
      "         4.43975714e+00,  3.79120993e-03, -1.89437603e+01]]), array([166.84007587, 166.84008612, 166.84009625, 166.84014612,\n",
      "       166.84014761, 166.840153  , 166.84016957]))\n",
      "           fun: 166.84007586992263\n",
      "       message: 'Maximum number of function evaluations has been exceeded.'\n",
      "          nfev: 1200\n",
      "           nit: 759\n",
      "        status: 1\n",
      "       success: False\n",
      "             x: array([-9.42909819e-02,  1.02272100e+00,  6.72904750e-03,  4.44254154e+00,\n",
      "        3.78591364e-03, -1.89650414e+01])\n"
     ]
    }
   ],
   "source": [
    "# lokal optimazation of the function\n",
    "print(scipy.optimize.minimize(neg_loglikelihood_ar1_Garch11,ar1_garch11_params_start,args=(r_t,),method= \"Nelder-Mead\",options={'ftol' : 1e-12}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stationary GARCH(1,1)** Stationary Conditions and Positivity Restrictions for the Variance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stationary mean equation:\n",
    "\\begin{equation}\n",
    "|\\phi_1| < 1\n",
    "\\end{equation}\n",
    "\n",
    "Stationary variance equation:\n",
    "\\begin{equation}\n",
    "\\alpha_1 + \\beta_1 < 1\n",
    "\\end{equation}\n",
    "\n",
    "Positive unconditional variance forecast:\n",
    "\\begin{equation}\n",
    "\\alpha_0 > 0 \\qquad \\text{and} \\qquad \\alpha_1, \\beta_1, \\sigma^2_{1} \\in \\mathcal{R}_+\n",
    "\\end{equation}\n",
    "\n",
    "Positive unconditional interest rates:\n",
    "\\begin{equation}\n",
    "\\phi_0 > 0, \\qquad \\phi_1 > 0\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bounded Optimization:** \n",
    "\n",
    "Hints:\n",
    "\n",
    "1. Please specify the bounds for all the parameters.\n",
    "\n",
    "2. For inequality constraints please following the doc from scipy in the following link:\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.differential_evolution.html. In addition, for $ \\alpha_1 + \\beta_1 < 1$ we specify it as $ 0<\\alpha_1 + \\beta_1 < 1$. \n",
    "\n",
    "3. Please use seed=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the length: number of unknown parameters\n",
    "K = len(ar1_garch11_params_start)\n",
    "\n",
    "def linearconstraint(params):\n",
    "    \"\"\"\n",
    "    :param params: Params list\n",
    "    :return: sum of the 2 variables\n",
    "    \"\"\"\n",
    "    return np.array(params[3] + params[4])\n",
    "\n",
    "# create a linaer constraint for the inequality\n",
    "constraint = scipy.optimize.NonlinearConstraint(linearconstraint,lb = 0, ub = 1)\n",
    "\n",
    "# lower bounds\n",
    "lb = 0.000001 * np.ones(K)\n",
    "\n",
    "# upper bounds\n",
    "ub = 1 * np.ones(K)\n",
    "\n",
    "# create the bounds\n",
    "bounds = tuple((lb[x],ub[x]) for x in range(0,K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\win10\\pycharmprojects\\elasticstack\\venv\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           constr: [array([0.])]\n",
      " constr_violation: 0.0\n",
      "              fun: -76.80268667510582\n",
      "              jac: [array([[0., 0., 0., 1., 1., 0.]]), array([[1., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 1.]])]\n",
      "            maxcv: 0.0\n",
      "          message: 'Optimization terminated successfully.'\n",
      "             nfev: 5996\n",
      "              nit: 93\n",
      "          success: True\n",
      "                x: array([4.95223831e-02, 9.91773641e-01, 2.26752586e-04, 1.44879680e-01,\n",
      "       8.55120292e-01, 2.80554551e-03])\n"
     ]
    }
   ],
   "source": [
    "# optimize globally\n",
    "optimal_values_globally = scipy.optimize.differential_evolution(func = neg_loglikelihood_ar1_Garch11,args=(r_t,),bounds = bounds,seed = 1,constraints = constraint)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}